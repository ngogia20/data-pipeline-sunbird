## Bootstrap for spark ##

- name: Adding ENV Vars to bashrc file of spark.
  become: yes
  become_user: "{{ analytics_user }}"
  lineinfile:
    path: '{{ analytics_user_home }}/.bashrc'
    line: 'export {{item.var}}={{item.value}}'
    regexp: "export {{ item.var }}.*"
  with_items:
    - {var: 'azure_storage_key', value: '{{ sunbird_private_storage_account_name }}'}
    - {var: 'azure_storage_secret', value: '{{ sunbird_private_storage_account_key }}'}

- name: Adding ENV Vars to spark servers environment.
  become: yes
  lineinfile:
    path: '/etc/environment'
    line: '{{item.var}}={{item.value}}'
    regexp: "{{ item.var }}.*"
  with_items:
    - {var: 'azure_storage_key', value: '{{ sunbird_private_storage_account_name }}'}
    - {var: 'azure_storage_secret', value: '{{ sunbird_private_storage_account_key }}'}
    - {var: 'AZURE_STORAGE_ACCOUNT', value: '{{ sunbird_private_storage_account_name }}'}
    - {var: 'AZURE_STORAGE_ACCESS_KEY', value: '{{ sunbird_private_storage_account_key }}'}
    - {var: 'GOOGLE_CREDENTIALS_PATH', value: '/home/analytics/credentials'}
    - {var: 'STORAGE_PROVIDER', value: 'AZURE'}
    - {var: 'ENV', value: '{{env}}'}
    - {var: 'KAFKA_BROKER_HOST', value: "{{groups['processing-cluster-kafka'][0]}}:9092"}

- name: Install required python packages
  become: yes
  action: apt pkg={{ item }} state=present update_cache=yes
  with_items:
    - libffi-dev
    - libssl-dev
    - build-essential
    - lzop
    - curl

- name: Install libraries for spark bootstrap
  become: yes
  action: apt pkg={{ item }} state=present update_cache=yes
  with_items:
    - build-essential
    - git

- name: Create directories for spark/data-products
  become: yes
  file: path={{ item }} owner={{ analytics_user }} group={{ analytics_group }} state=directory
  with_items: "{{ analytics.paths }}"
